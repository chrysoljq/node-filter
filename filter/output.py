"""è¾“å‡ºæ¨¡å—ã€‚

ç”Ÿæˆç­›é€‰åçš„ mihomo/Clash YAML é…ç½®æ–‡ä»¶ã€‚
"""

import logging
import requests
from datetime import datetime, timezone
from pathlib import Path

import yaml

logger = logging.getLogger(__name__)


def push_to_worker(content: str, url: str, token: str = None, data_type: str = "yaml") -> bool:
    """å°†é…ç½®å†…å®¹æ¨é€åˆ°è¿œç¨‹ Workerã€‚

    Args:
        content: è¦æ¨é€çš„å†…å®¹
        url: Worker çš„ API æ¥å£åœ°å€ï¼ˆå¦‚ .../api/yaml æˆ– .../api/reportï¼‰
        token: é‰´æƒ Token
        data_type: æ•°æ®ç±»å‹ï¼Œ'yaml' æˆ– 'report'
    """
    try:
        headers = {"Content-Type": "application/json"}
        params = {}
        if token:
            params["token"] = token

        payload = {data_type: content}
        resp = requests.post(url, json=payload, params=params, headers=headers, timeout=30)
        resp.raise_for_status()
        logger.info("å†…å®¹å·²æˆåŠŸæ¨é€åˆ°è¿œç¨‹ Worker: %s (%s)", url, data_type)
        return True
    except Exception as e:
        logger.error("æ¨é€åˆ°è¿œç¨‹ Worker å¤±è´¥ (%s): %s", data_type, e)
        return False


# é»˜è®¤çš„ä»£ç†ç»„æ¨¡æ¿
_DEFAULT_PROXY_GROUPS = [
    {
        "name": "ğŸš€ èŠ‚ç‚¹é€‰æ‹©",
        "type": "select",
        "proxies": ["â™»ï¸ è‡ªåŠ¨é€‰æ‹©", "DIRECT"],
    },
    {
        "name": "â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
        "type": "url-test",
        "url": "https://www.gstatic.com/generate_204",
        "interval": 300,
        "tolerance": 50,
        "proxies": [],
    },
]

# é»˜è®¤è§„åˆ™
_DEFAULT_RULES = [
    "GEOIP,LAN,DIRECT",
    "GEOIP,CN,DIRECT",
    "MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©",
]


def _clean_proxy(proxy: dict) -> dict:
    """ç§»é™¤å†…éƒ¨æ ‡è®°å­—æ®µã€‚"""
    return {k: v for k, v in proxy.items() if not k.startswith("_")}


def generate_mihomo_config(
    proxies: list[dict],
    output_path: str | Path,
    mixed_port: int = 7890,
    api_port: int = 9090,
    extra_proxy_groups: list[dict] | None = None,
    extra_rules: list[str] | None = None,
    test_results: list[dict] | None = None,
) -> Path:
    """ç”Ÿæˆå®Œæ•´çš„ mihomo é…ç½®æ–‡ä»¶ã€‚

    Args:
        proxies: ç­›é€‰åçš„èŠ‚ç‚¹åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        mixed_port: æ··åˆä»£ç†ç«¯å£
        api_port: API ç«¯å£
        extra_proxy_groups: é¢å¤–çš„ä»£ç†ç»„
        extra_rules: é¢å¤–çš„è§„åˆ™
        test_results: è¿é€šæ€§æµ‹è¯•ç»“æœï¼ˆç”¨äºæ·»åŠ å»¶è¿Ÿä¿¡æ¯åˆ°èŠ‚ç‚¹åï¼‰
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # æ¸…ç†èŠ‚ç‚¹
    clean_proxies = [_clean_proxy(p) for p in proxies]

    if not clean_proxies:
        logger.warning("æ²¡æœ‰å¯ç”¨èŠ‚ç‚¹ï¼Œç”Ÿæˆç©ºé…ç½®")

    # èŠ‚ç‚¹ååˆ—è¡¨
    proxy_names = [p["name"] for p in clean_proxies]

    # æ„å»ºä»£ç†ç»„
    proxy_groups = []
    for group in _DEFAULT_PROXY_GROUPS:
        g = dict(group)
        if g["name"] == "ğŸš€ èŠ‚ç‚¹é€‰æ‹©":
            g["proxies"] = ["â™»ï¸ è‡ªåŠ¨é€‰æ‹©", "DIRECT"] + proxy_names
        elif g["name"] == "â™»ï¸ è‡ªåŠ¨é€‰æ‹©":
            g["proxies"] = proxy_names.copy()
        proxy_groups.append(g)

    if extra_proxy_groups:
        proxy_groups.extend(extra_proxy_groups)

    # æ„å»ºè§„åˆ™
    rules = list(extra_rules) if extra_rules else list(_DEFAULT_RULES)

    # æ„å»ºå®Œæ•´é…ç½®
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
    config = {
        "# ç”± mihomo-node-filter è‡ªåŠ¨ç”Ÿæˆ": None,
        "# æ›´æ–°æ—¶é—´": now,
        "mixed-port": mixed_port,
        "allow-lan": False,
        "mode": "rule",
        "log-level": "info",
        "ipv6": False,
        "external-controller": f"127.0.0.1:{api_port}",
        "dns": {
            "enable": True,
            "enhanced-mode": "fake-ip",
            "fake-ip-range": "198.18.0.1/16",
            "nameserver": [
                "https://doh.pub/dns-query",
                "https://dns.alidns.com/dns-query",
            ],
        },
        "proxies": clean_proxies,
        "proxy-groups": proxy_groups,
        "rules": rules,
    }

    # è‡ªå®šä¹‰ YAML è¾“å‡ºï¼Œå»æ‰ None å€¼çš„æ³¨é‡Šè¡Œ
    lines = []
    lines.append(f"# ç”± mihomo-node-filter è‡ªåŠ¨ç”Ÿæˆ")
    lines.append(f"# æ›´æ–°æ—¶é—´: {now}")
    lines.append(f"# èŠ‚ç‚¹æ•°é‡: {len(clean_proxies)}")
    lines.append("")

    # ç§»é™¤æ³¨é‡Šé”®
    config.pop("# ç”± mihomo-node-filter è‡ªåŠ¨ç”Ÿæˆ", None)
    config.pop("# æ›´æ–°æ—¶é—´", None)

    yaml_content = yaml.dump(
        config,
        allow_unicode=True,
        default_flow_style=False,
        sort_keys=False,
    )

    full_content = "\n".join(lines) + yaml_content

    output_path.write_text(full_content, encoding="utf-8")
    logger.info("é…ç½®æ–‡ä»¶å·²å†™å…¥: %s (%d ä¸ªèŠ‚ç‚¹)", output_path, len(clean_proxies))
    return output_path


def generate_proxy_list(
    proxies: list[dict],
    output_path: str | Path,
) -> Path:
    """ç”Ÿæˆä»…åŒ…å« proxies åˆ—è¡¨çš„ YAMLï¼ˆæ–¹ä¾¿åµŒå…¥å…¶ä»–é…ç½®ï¼‰ã€‚"""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    clean_proxies = [_clean_proxy(p) for p in proxies]
    content = yaml.dump(
        {"proxies": clean_proxies},
        allow_unicode=True,
        default_flow_style=False,
        sort_keys=False,
    )

    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
    header = (
        f"# ç”± mihomo-node-filter è‡ªåŠ¨ç”Ÿæˆ\n"
        f"# æ›´æ–°æ—¶é—´: {now}\n"
        f"# èŠ‚ç‚¹æ•°é‡: {len(clean_proxies)}\n"
        f"\n"
    )

    output_path.write_text(header + content, encoding="utf-8")
    logger.info("èŠ‚ç‚¹åˆ—è¡¨å·²å†™å…¥: %s (%d ä¸ªèŠ‚ç‚¹)", output_path, len(clean_proxies))
    return output_path


def generate_report(
    residential: list[dict],
    datacenter: list[dict],
    unknown: list[dict],
    test_results: list[dict] | None,
    output_path: str | Path,
) -> Path:
    """ç”Ÿæˆç­›é€‰æŠ¥å‘Šã€‚"""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")

    lines = [
        f"# èŠ‚ç‚¹ç­›é€‰æŠ¥å‘Š",
        f"# ç”Ÿæˆæ—¶é—´: {now}",
        "",
        f"## æ€»è®¡",
        f"- ä½å®…èŠ‚ç‚¹: {len(residential)}",
        f"- æœºæˆ¿èŠ‚ç‚¹: {len(datacenter)}",
        f"- æœªçŸ¥èŠ‚ç‚¹: {len(unknown)}",
        "",
    ]

    if residential:
        lines.append("## ä½å®…èŠ‚ç‚¹ï¼ˆä¿ç•™ï¼‰")
        for p in residential:
            name = p.get("name", "unknown")
            ip = p.get("_exit_ip", p.get("_entry_ip", ""))
            org = p.get("_exit_org", p.get("_entry_org", ""))
            cc = p.get("_exit_country", p.get("_entry_country", ""))
            delay = p.get("_delay", "")
            delay_str = f" | {delay}ms" if delay else ""
            
            unlock_str = ""
            if "_unlock" in p:
                unlocked_svcs = [k for k, v in p["_unlock"].items() if v]
                unlock_str = f" | è§£é”: {', '.join(unlocked_svcs) if unlocked_svcs else 'æ— '}"
                
            lines.append(f"- {name} | {ip} | {org} | {cc}{delay_str}{unlock_str}")
        lines.append("")

    if datacenter:
        lines.append("## æœºæˆ¿èŠ‚ç‚¹ï¼ˆè¿‡æ»¤ï¼‰")
        for p in datacenter:
            name = p.get("name", "unknown")
            ip = p.get("_exit_ip", p.get("_entry_ip", ""))
            org = p.get("_exit_org", p.get("_entry_org", ""))
            reason = p.get("_filter_reason", "")
            lines.append(f"- {name} | {ip} | {org} | åŸå› : {reason}")
        lines.append("")

    if test_results:
        alive = [r for r in test_results if r["alive"]]
        dead = [r for r in test_results if not r["alive"]]
        lines.append("## è¿é€šæ€§æµ‹è¯•")
        lines.append(f"- å­˜æ´»: {len(alive)}")
        lines.append(f"- å¤±è´¥: {len(dead)}")
        if alive:
            lines.append("")
            lines.append("### å­˜æ´»èŠ‚ç‚¹")
            for r in sorted(alive, key=lambda x: x["delay"]):
                lines.append(f"- {r['name']} | {r['delay']}ms")
        if dead:
            lines.append("")
            lines.append("### å¤±è´¥èŠ‚ç‚¹")
            for r in dead:
                lines.append(f"- {r['name']} | {r.get('error', 'unknown')}")
                
    if test_results and any("unlock" in r for r in test_results):
        lines.append("")
        lines.append("## AI è§£é”æ£€æµ‹")
        for r in [r for r in test_results if r["alive"] and "unlock" in r]:
            unlock_dict = r["unlock"]
            if not unlock_dict:
                continue
            status_list = [f"{k}: {'âœ“' if v else 'âœ—'}" for k, v in unlock_dict.items()]
            lines.append(f"- {r['name']} | " + " | ".join(status_list))

    output_path.write_text("\n".join(lines), encoding="utf-8")
    logger.info("æŠ¥å‘Šå·²å†™å…¥: %s", output_path)
    return output_path
